{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "b09_classification_modelling_stacking.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiL_bkC6QrYc",
        "colab_type": "text"
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Description\" data-toc-modified-id=\"Data-Description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Description</a></span></li><li><span><a href=\"#Business-Problem\" data-toc-modified-id=\"Business-Problem-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Business Problem</a></span></li><li><span><a href=\"#Introduction-to-Pycaret\" data-toc-modified-id=\"Introduction-to-Pycaret-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Introduction to Pycaret</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Useful-Functions\" data-toc-modified-id=\"Useful-Functions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Useful Functions</a></span></li><li><span><a href=\"#Load-the-data\" data-toc-modified-id=\"Load-the-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Load the data</a></span></li><li><span><a href=\"#Train-test-split-with-stratify\" data-toc-modified-id=\"Train-test-split-with-stratify-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Train test split with stratify</a></span></li><li><span><a href=\"#Pycaret-Setup\" data-toc-modified-id=\"Pycaret-Setup-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Pycaret Setup</a></span></li><li><span><a href=\"#Comparing-All-Models\" data-toc-modified-id=\"Comparing-All-Models-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Comparing All Models</a></span></li><li><span><a href=\"#Create-Models\" data-toc-modified-id=\"Create-Models-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Create Models</a></span></li><li><span><a href=\"#Hyperparameter-Tuning\" data-toc-modified-id=\"Hyperparameter-Tuning-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Hyperparameter Tuning</a></span></li><li><span><a href=\"#Further-tuning\" data-toc-modified-id=\"Further-tuning-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Further tuning</a></span></li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Model Evaluation</a></span></li><li><span><a href=\"#Ensemble--Modelling\" data-toc-modified-id=\"Ensemble--Modelling-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Ensemble  Modelling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bagging\" data-toc-modified-id=\"Bagging-14.1\"><span class=\"toc-item-num\">14.1&nbsp;&nbsp;</span>Bagging</a></span></li><li><span><a href=\"#Boosting\" data-toc-modified-id=\"Boosting-14.2\"><span class=\"toc-item-num\">14.2&nbsp;&nbsp;</span>Boosting</a></span></li><li><span><a href=\"#Blending\" data-toc-modified-id=\"Blending-14.3\"><span class=\"toc-item-num\">14.3&nbsp;&nbsp;</span>Blending</a></span></li><li><span><a href=\"#Stacking\" data-toc-modified-id=\"Stacking-14.4\"><span class=\"toc-item-num\">14.4&nbsp;&nbsp;</span>Stacking</a></span></li></ul></li><li><span><a href=\"#Model-Calibration\" data-toc-modified-id=\"Model-Calibration-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Model Calibration</a></span></li><li><span><a href=\"#Model-Interpretation\" data-toc-modified-id=\"Model-Interpretation-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>Model Interpretation</a></span></li><li><span><a href=\"#Model-Predictions\" data-toc-modified-id=\"Model-Predictions-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span>Model Predictions</a></span></li><li><span><a href=\"#Model-Persistence\" data-toc-modified-id=\"Model-Persistence-18\"><span class=\"toc-item-num\">18&nbsp;&nbsp;</span>Model Persistence</a></span></li><li><span><a href=\"#Time-taken\" data-toc-modified-id=\"Time-taken-19\"><span class=\"toc-item-num\">19&nbsp;&nbsp;</span>Time taken</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF0vfOSoRKbV",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Kernel Author:</b>  <br>\n",
        "<a href=\"https://bhishanpdl.github.io/\" , target=\"_blank\">Bhishan Poudel,  Data Scientist, Ph.D Astrophysics</a> .\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrcXZt_lRUTH",
        "colab_type": "text"
      },
      "source": [
        "# Data Description\n",
        "\n",
        "> The datasets contains transactions made by credit cards in September\n",
        "2013 by european cardholders.\n",
        "\n",
        "\n",
        "> This dataset presents transactions that occurred in two days,\n",
        "where we have 492 frauds out of 284,807 transactions. \n",
        "\n",
        "> The dataset is highly unbalanced, the positive class (frauds)\n",
        "account for 0.172% of all transactions.\n",
        "\n",
        "> It contains only numerical input variables which are\n",
        "the result of a PCA transformation.\n",
        "\n",
        "\n",
        "> Unfortunately, due to confidentiality issues,\n",
        "we cannot provide the original features and \n",
        "more background information about the data.\n",
        "\n",
        "\n",
        "> Features V1, V2, ... V28 are the principal\n",
        "components obtained with PCA,\n",
        "the only features which have not been transformed with PCA are 'Time' and 'Amount'. \n",
        "\n",
        "> Feature 'Time' contains the seconds elapsed between each transaction\n",
        "and the first transaction in the dataset. The feature 'Amount'\n",
        "is the transaction Amount, this feature can be used for \n",
        "example-dependant cost-senstive learning. \n",
        "\n",
        "> Feature 'Class' is the response variable and it takes value\n",
        "1 in case of fraud and 0 otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z46Gwfc3Rcwk",
        "colab_type": "text"
      },
      "source": [
        "# Business Problem\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Business Problem:</b>  <br>\n",
        "Task &nbsp;&nbsp; : Detect the fraudulent activities. <br>\n",
        "Metric : Recall <br>\n",
        "Sampling: Synthetic Minority Over-Sampling Technique (SMOTE) <br>\n",
        "Question: How many frauds are correctly classified?\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vuUeq0iRjZn",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv0HTLcCRdfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "time_start_notebook = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fLyC776RmGc",
        "colab_type": "code",
        "outputId": "30e8ac1d-c173-4ecc-cb0c-55d8f3b4de4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use('ggplot') \n",
        "\n",
        "# random state\n",
        "SEED=100\n",
        "\n",
        "home = os.path.expanduser('~')\n",
        "\n",
        "[(x.__name__,x.__version__) for x in [np,pd,sns]]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('numpy', '1.18.4'), ('pandas', '1.0.4'), ('seaborn', '0.10.1')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scVctCs7HnQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Models\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4omENGYRoW5",
        "colab_type": "code",
        "outputId": "4f1e0cd4-08fe-406f-d5c0-a5d25b3ce2a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "import sys\n",
        "ENV_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if ENV_COLAB:\n",
        "    !pip install catboost\n",
        "    print('Environment: Google Colab')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/aa/e61819d04ef2bbee778bf4b3a748db1f3ad23512377e43ecfdc3211437a0/catboost-0.23.2-cp36-none-manylinux1_x86_64.whl (64.8MB)\n",
            "\u001b[K     |████████████████████████████████| 64.8MB 68kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.0.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.23.2\n",
            "Environment: Google Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2I2KshNSGUi",
        "colab_type": "text"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjmdL7RRSD1r",
        "colab_type": "code",
        "outputId": "f0b67b7d-9ce4-49de-dd20-49dc06bf2ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "ifile = 'https://github.com/bhishanpdl/Datasets/blob/master/fraud_detection/creditcard.csv.zip?raw=true'\n",
        "df = pd.read_csv(ifile,compression='zip')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(284807, 31)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-41_1myzOmfV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "fcea84e0-5266-416a-a4a9-7b2280ca4aaf"
      },
      "source": [
        "target = 'Class'\n",
        "features = df.columns.drop(target)\n",
        "df[target].value_counts(normalize=True)*100"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    99.827251\n",
              "1     0.172749\n",
              "Name: Class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w5eQBpkOqw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "a522d8ab-9719-44b6-d3af-e9cd459551d2"
      },
      "source": [
        "sns.countplot(df[target])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe5c3799c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 410,
              "height": 264
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NRtTZS8M3sJ",
        "colab_type": "text"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9XYITLUSWpA",
        "colab_type": "text"
      },
      "source": [
        "# Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odBF6q99STp2",
        "colab_type": "code",
        "outputId": "52dc9ee7-d23e-4176-ad55-cc6406c17371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_Xtrain_orig, df_Xtest, ser_ytrain_orig, ser_ytest = train_test_split(\n",
        "    df.drop(target,axis=1), \n",
        "    df[target],\n",
        "    test_size=0.2, \n",
        "    random_state=SEED, \n",
        "    stratify=df[target])\n",
        "\n",
        "ytrain_orig = ser_ytrain_orig.to_numpy().ravel()\n",
        "ytest = ser_ytest.to_numpy().ravel()\n",
        "\n",
        "print(df_Xtrain_orig.shape)\n",
        "df_Xtrain_orig.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(227845, 30)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>211885</th>\n",
              "      <td>138616.0</td>\n",
              "      <td>-1.137612</td>\n",
              "      <td>2.345154</td>\n",
              "      <td>-1.767247</td>\n",
              "      <td>0.833982</td>\n",
              "      <td>0.973168</td>\n",
              "      <td>-0.073571</td>\n",
              "      <td>0.802433</td>\n",
              "      <td>0.733137</td>\n",
              "      <td>-1.154087</td>\n",
              "      <td>-0.520340</td>\n",
              "      <td>0.494117</td>\n",
              "      <td>0.799935</td>\n",
              "      <td>0.494576</td>\n",
              "      <td>-0.479666</td>\n",
              "      <td>-0.917177</td>\n",
              "      <td>-0.184117</td>\n",
              "      <td>1.189459</td>\n",
              "      <td>0.937244</td>\n",
              "      <td>0.960749</td>\n",
              "      <td>0.062820</td>\n",
              "      <td>0.114953</td>\n",
              "      <td>0.430613</td>\n",
              "      <td>-0.240819</td>\n",
              "      <td>0.124011</td>\n",
              "      <td>0.187187</td>\n",
              "      <td>-0.402251</td>\n",
              "      <td>0.196277</td>\n",
              "      <td>0.190732</td>\n",
              "      <td>39.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12542</th>\n",
              "      <td>21953.0</td>\n",
              "      <td>-1.028649</td>\n",
              "      <td>1.141569</td>\n",
              "      <td>2.492561</td>\n",
              "      <td>-0.242233</td>\n",
              "      <td>0.452842</td>\n",
              "      <td>-0.384273</td>\n",
              "      <td>1.256026</td>\n",
              "      <td>-0.816401</td>\n",
              "      <td>1.964560</td>\n",
              "      <td>-0.014216</td>\n",
              "      <td>0.432153</td>\n",
              "      <td>-2.140921</td>\n",
              "      <td>2.274477</td>\n",
              "      <td>0.114128</td>\n",
              "      <td>-1.652894</td>\n",
              "      <td>-0.617302</td>\n",
              "      <td>0.243791</td>\n",
              "      <td>-0.426168</td>\n",
              "      <td>-0.493177</td>\n",
              "      <td>0.350032</td>\n",
              "      <td>-0.380356</td>\n",
              "      <td>-0.037432</td>\n",
              "      <td>-0.503934</td>\n",
              "      <td>0.407129</td>\n",
              "      <td>0.604252</td>\n",
              "      <td>0.233015</td>\n",
              "      <td>-0.433132</td>\n",
              "      <td>-0.491892</td>\n",
              "      <td>7.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270932</th>\n",
              "      <td>164333.0</td>\n",
              "      <td>-1.121864</td>\n",
              "      <td>-0.195099</td>\n",
              "      <td>1.282634</td>\n",
              "      <td>-3.172847</td>\n",
              "      <td>-0.761969</td>\n",
              "      <td>-0.287013</td>\n",
              "      <td>-0.586367</td>\n",
              "      <td>0.496182</td>\n",
              "      <td>-2.352349</td>\n",
              "      <td>0.350551</td>\n",
              "      <td>-1.319688</td>\n",
              "      <td>-0.942001</td>\n",
              "      <td>1.082210</td>\n",
              "      <td>-0.425735</td>\n",
              "      <td>0.036748</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>-0.033353</td>\n",
              "      <td>0.204609</td>\n",
              "      <td>-0.801465</td>\n",
              "      <td>-0.113632</td>\n",
              "      <td>-0.328953</td>\n",
              "      <td>-0.856937</td>\n",
              "      <td>-0.056198</td>\n",
              "      <td>0.401905</td>\n",
              "      <td>0.406813</td>\n",
              "      <td>-0.440140</td>\n",
              "      <td>0.152356</td>\n",
              "      <td>0.030128</td>\n",
              "      <td>40.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30330</th>\n",
              "      <td>35874.0</td>\n",
              "      <td>1.094238</td>\n",
              "      <td>-0.760568</td>\n",
              "      <td>-0.392822</td>\n",
              "      <td>-0.611720</td>\n",
              "      <td>-0.722850</td>\n",
              "      <td>-0.851978</td>\n",
              "      <td>-0.185505</td>\n",
              "      <td>-0.095131</td>\n",
              "      <td>-1.122304</td>\n",
              "      <td>0.367009</td>\n",
              "      <td>1.378493</td>\n",
              "      <td>-0.724216</td>\n",
              "      <td>-1.105406</td>\n",
              "      <td>-0.480170</td>\n",
              "      <td>0.220826</td>\n",
              "      <td>1.745743</td>\n",
              "      <td>0.740817</td>\n",
              "      <td>-0.728827</td>\n",
              "      <td>1.016740</td>\n",
              "      <td>0.354148</td>\n",
              "      <td>-0.227392</td>\n",
              "      <td>-1.254285</td>\n",
              "      <td>0.022116</td>\n",
              "      <td>-0.141531</td>\n",
              "      <td>0.114515</td>\n",
              "      <td>-0.652427</td>\n",
              "      <td>-0.037897</td>\n",
              "      <td>0.051254</td>\n",
              "      <td>165.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272477</th>\n",
              "      <td>165107.0</td>\n",
              "      <td>2.278095</td>\n",
              "      <td>-1.298924</td>\n",
              "      <td>-1.884035</td>\n",
              "      <td>-1.530435</td>\n",
              "      <td>-0.649500</td>\n",
              "      <td>-0.996024</td>\n",
              "      <td>-0.466776</td>\n",
              "      <td>-0.438025</td>\n",
              "      <td>-1.612665</td>\n",
              "      <td>1.631133</td>\n",
              "      <td>-1.126000</td>\n",
              "      <td>-0.938760</td>\n",
              "      <td>0.300621</td>\n",
              "      <td>-0.119667</td>\n",
              "      <td>-0.585453</td>\n",
              "      <td>-1.106244</td>\n",
              "      <td>0.690235</td>\n",
              "      <td>-0.124401</td>\n",
              "      <td>-0.075649</td>\n",
              "      <td>-0.341708</td>\n",
              "      <td>0.123892</td>\n",
              "      <td>0.815909</td>\n",
              "      <td>-0.072537</td>\n",
              "      <td>0.784217</td>\n",
              "      <td>0.403428</td>\n",
              "      <td>0.193747</td>\n",
              "      <td>-0.043185</td>\n",
              "      <td>-0.058719</td>\n",
              "      <td>60.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2  ...       V27       V28  Amount\n",
              "211885  138616.0 -1.137612  2.345154  ...  0.196277  0.190732   39.46\n",
              "12542    21953.0 -1.028649  1.141569  ... -0.433132 -0.491892    7.19\n",
              "270932  164333.0 -1.121864 -0.195099  ...  0.152356  0.030128   40.00\n",
              "30330    35874.0  1.094238 -0.760568  ... -0.037897  0.051254  165.85\n",
              "272477  165107.0  2.278095 -1.298924  ... -0.043185 -0.058719   60.00\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3yzn9G7O60C",
        "colab_type": "text"
      },
      "source": [
        "# Train Validation with stratify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYmdSn4BO-m5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83dd43dc-c214-4da1-cd99-50068ab84c73"
      },
      "source": [
        "df_Xtrain, df_Xvalid, ser_ytrain, ser_yvalid = train_test_split(\n",
        "    df_Xtrain_orig, \n",
        "    ser_ytrain_orig,\n",
        "    test_size=0.2, \n",
        "    random_state=SEED, \n",
        "    stratify=ser_ytrain_orig)\n",
        "\n",
        "\n",
        "ytrain = ser_ytrain.to_numpy().ravel()\n",
        "yvalid = ser_yvalid.to_numpy().ravel()\n",
        "\n",
        "print(df_Xtrain.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(182276, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkC5n6muJSeS",
        "colab_type": "text"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7zZFCfgXSeE",
        "colab_type": "text"
      },
      "source": [
        "## Setup Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36x5YEUiWyp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "lda = LinearDiscriminantAnalysis(n_components=None,\n",
        "                           priors=None,\n",
        "                           shrinkage=None,\n",
        "                           solver='svd',\n",
        "                           store_covariance=False,\n",
        "                           tol=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfTZ7_ecSvtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "\n",
        "xgboost = XGBClassifier(base_score=0.5, booster='gbtree', boosting_type='gbdt',\n",
        "              colsample_by_tree=0.8040279979830232, colsample_bylevel=1,\n",
        "              colsample_bytree=1, gamma=0, learning_rate=0.6183443388044544,\n",
        "              max_delta_step=0, max_depth=7, min_child_weight=3.0, missing=None,\n",
        "              n_estimators=150, n_jobs=-1, nthread=None, num_leaves=37,\n",
        "              objective='binary:logistic', random_state=100, reg_alpha=0,\n",
        "              reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
        "              subsample=0.8254724276776704)\n",
        "\n",
        "lightgbm_params = {'bagging_fraction': 0.5847570898839785,\n",
        " 'bagging_freq': 3,\n",
        " 'feature_fraction': 0.7941666171144979,\n",
        " 'lambda_l1': 1.3871523892529368e-07,\n",
        " 'lambda_l2': 0.44361819101899735,\n",
        " 'min_child_samples': 55,\n",
        " 'min_child_weight': 5.899155081455939,\n",
        " 'num_leaves': 156,\n",
        " 'subsample': 0.7122064897274488}\n",
        "lightgbm = LGBMClassifier(random_state=SEED, **lightgbm_params)\n",
        "\n",
        "catboost = CatBoostClassifier(verbose=False,random_state=100,\n",
        "                            depth=6,\n",
        "                            iterations=1_000,\n",
        "                            )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wImdN4I1Xopk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stack up all the models\n",
        "from mlxtend.classifier import StackingCVClassifier\n",
        "\n",
        "stack = StackingCVClassifier(classifiers=(lda,xgboost, lightgbm, catboost),\n",
        "                                meta_classifier=xgboost,\n",
        "                                use_features_in_secondary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RuLXvkNbxtO",
        "colab_type": "text"
      },
      "source": [
        "# Fit the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6r0ZKyBa1WS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1b69bfbe-1f4e-4e94-ebf0-1ad1bca6a8e2"
      },
      "source": [
        "%%time\n",
        "lda.fit(np.array(df_Xtrain),np.array(ser_ytrain));"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.1 s, sys: 48.9 ms, total: 1.15 s\n",
            "Wall time: 931 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
              "                           solver='svd', store_covariance=False, tol=0.0001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spAnU2Naa1eI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "7dc879aa-879d-4ef4-8fae-465aa117ca82"
      },
      "source": [
        "%%time\n",
        "xgboost.fit(np.array(df_Xtrain),np.array(ser_ytrain));"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 36s, sys: 52.6 ms, total: 1min 36s\n",
            "Wall time: 49.1 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', boosting_type='gbdt',\n",
              "              colsample_by_tree=0.8040279979830232, colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.6183443388044544, max_delta_step=0, max_depth=7,\n",
              "              min_child_weight=3.0, missing=None, n_estimators=150, n_jobs=-1,\n",
              "              nthread=None, num_leaves=37, objective='binary:logistic',\n",
              "              random_state=100, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "              seed=None, silent=True, subsample=0.8254724276776704,\n",
              "              verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxCHN6A-a1mx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "d20a0e63-a297-45ae-8419-aac5f47b2ca5"
      },
      "source": [
        "%%time\n",
        "lightgbm.fit(np.array(df_Xtrain),np.array(ser_ytrain));"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.42 s, sys: 23.4 ms, total: 5.45 s\n",
            "Wall time: 2.85 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(bagging_fraction=0.5847570898839785, bagging_freq=3,\n",
              "               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "               feature_fraction=0.7941666171144979, importance_type='split',\n",
              "               lambda_l1=1.3871523892529368e-07, lambda_l2=0.44361819101899735,\n",
              "               learning_rate=0.1, max_depth=-1, min_child_samples=55,\n",
              "               min_child_weight=5.899155081455939, min_split_gain=0.0,\n",
              "               n_estimators=100, n_jobs=-1, num_leaves=156, objective=None,\n",
              "               random_state=100, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=0.7122064897274488, subsample_for_bin=200000,\n",
              "               subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBOFF1rBa-kp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3cef4070-1210-4ffc-8800-bf7a92ea95bb"
      },
      "source": [
        "%%time\n",
        "catboost.fit(np.array(df_Xtrain),np.array(ser_ytrain));"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 33s, sys: 7.38 s, total: 2min 40s\n",
            "Wall time: 1min 22s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fe5aba6b7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7HqA9Ai5iWW",
        "colab_type": "code",
        "outputId": "b3b91a82-7ff7-4746-e341-b3c30a9d9a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "%%time\n",
        "stack.fit(np.array(df_Xtrain),np.array(ser_ytrain));"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10min 14s, sys: 18.5 s, total: 10min 33s\n",
            "Wall time: 5min 24s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingCVClassifier(classifiers=(LinearDiscriminantAnalysis(n_components=None,\n",
              "                                                             priors=None,\n",
              "                                                             shrinkage=None,\n",
              "                                                             solver='svd',\n",
              "                                                             store_covariance=False,\n",
              "                                                             tol=0.0001),\n",
              "                                  XGBClassifier(base_score=0.5,\n",
              "                                                booster='gbtree',\n",
              "                                                boosting_type='gbdt',\n",
              "                                                colsample_by_tree=0.8040279979830232,\n",
              "                                                colsample_bylevel=1,\n",
              "                                                colsample_bynode=1,\n",
              "                                                colsample_bytree=1, gamma=0,\n",
              "                                                learning_rate=0.6183443388...\n",
              "                                                   missing=None,\n",
              "                                                   n_estimators=150, n_jobs=-1,\n",
              "                                                   nthread=None, num_leaves=37,\n",
              "                                                   objective='binary:logistic',\n",
              "                                                   random_state=100,\n",
              "                                                   reg_alpha=0, reg_lambda=1,\n",
              "                                                   scale_pos_weight=1,\n",
              "                                                   seed=None, silent=True,\n",
              "                                                   subsample=0.8254724276776704,\n",
              "                                                   verbosity=1),\n",
              "                     shuffle=True, store_train_meta_features=False,\n",
              "                     stratify=True, use_clones=True,\n",
              "                     use_features_in_secondary=True, use_probas=False,\n",
              "                     verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2hVnXkNVXmR",
        "colab_type": "text"
      },
      "source": [
        "# Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ti429GMUzxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cbbf53a9-6d4f-455d-b576-7735470ae074"
      },
      "source": [
        "%%time\n",
        "ypreds_lda = lda.predict(np.array(df_Xtest))\n",
        "ypreds_xgboost = xgboost.predict(np.array(df_Xtest))\n",
        "ypreds_lightgbm = lightgbm.predict(np.array(df_Xtest))\n",
        "ypreds_catboost = catboost.predict(np.array(df_Xtest))\n",
        "ypreds_stack = stack.predict(np.array(df_Xtest))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.29 s, sys: 173 ms, total: 2.47 s\n",
            "Wall time: 1.28 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RaRcfF2Vs9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytest = np.array(ser_ytest).ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unAhA54cU_H9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "074ed724-94ca-4220-dfeb-3da332fd7372"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "ypreds = [ypreds_lda, ypreds_xgboost, ypreds_lightgbm,ypreds_catboost,ypreds_stack]\n",
        "model_names = ['lda','xgboost','lightgbm','catboost','stack']\n",
        "wrong_frauds = [confusion_matrix(ytest,ypred)[1,0] for ypred in ypreds]\n",
        "accuracies = [accuracy_score(ytest,ypred) for ypred in ypreds]\n",
        "precisions = [precision_score(ytest,ypred) for ypred in ypreds]\n",
        "recalls = [recall_score(ytest,ypred) for ypred in ypreds]\n",
        "f1_scores = [f1_score(ytest,ypred) for ypred in ypreds]\n",
        "\n",
        "df_eval = pd.DataFrame({'Model': model_names,\n",
        "                        'WrongFrauds': wrong_frauds,\n",
        "                        'Accuracy': accuracies,\n",
        "                        'Precision': precisions,\n",
        "                        'Recall': recalls,\n",
        "                        'F1-score': f1_scores})\n",
        "\n",
        "\n",
        "df_eval = df_eval.sort_values('Recall',ascending=False)\n",
        "df_eval"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>WrongFrauds</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lightgbm</td>\n",
              "      <td>19</td>\n",
              "      <td>0.999596</td>\n",
              "      <td>0.951807</td>\n",
              "      <td>0.806122</td>\n",
              "      <td>0.872928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xgboost</td>\n",
              "      <td>20</td>\n",
              "      <td>0.999614</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.795918</td>\n",
              "      <td>0.876404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>stack</td>\n",
              "      <td>20</td>\n",
              "      <td>0.999614</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.795918</td>\n",
              "      <td>0.876404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>catboost</td>\n",
              "      <td>22</td>\n",
              "      <td>0.999561</td>\n",
              "      <td>0.962025</td>\n",
              "      <td>0.775510</td>\n",
              "      <td>0.858757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lda</td>\n",
              "      <td>25</td>\n",
              "      <td>0.999333</td>\n",
              "      <td>0.848837</td>\n",
              "      <td>0.744898</td>\n",
              "      <td>0.793478</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Model  WrongFrauds  Accuracy  Precision    Recall  F1-score\n",
              "2  lightgbm           19  0.999596   0.951807  0.806122  0.872928\n",
              "1   xgboost           20  0.999614   0.975000  0.795918  0.876404\n",
              "4     stack           20  0.999614   0.975000  0.795918  0.876404\n",
              "3  catboost           22  0.999561   0.962025  0.775510  0.858757\n",
              "0       lda           25  0.999333   0.848837  0.744898  0.793478"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txe1mcGOVyjP",
        "colab_type": "code",
        "outputId": "5defd0a2-a21d-4910-ed1e-8d9a9e3fd36a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(ytest,ypreds_stack)\n",
        "print(cm)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[56862     2]\n",
            " [   20    78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9m3xCQcV9OS",
        "colab_type": "code",
        "outputId": "7e8fbdb7-79a6-4fc4-c64d-56f00d59870e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wrong_frauds = cm[1,0]\n",
        "wrong_frauds"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f0pi1oSbhYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}