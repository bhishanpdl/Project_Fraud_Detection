{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "b05_classification_modelling_boosting_xgboost.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMgpqhTv1olf",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to Boosting\n",
        "References: \n",
        "- https://github.com/dmlc/xgboost/tree/master/demo/guide-python\n",
        "- https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/\n",
        "- https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
        "- http://xgboost.readthedocs.org/en/latest/parameter.html#general-parameters\n",
        "- https://github.com/dmlc/xgboost/tree/master/demo/guide-python\n",
        "- https://xgboost.readthedocs.io/en/latest/python/python_api.html\n",
        "\n",
        "The term `Boosting` refers to a family of algorithms which converts weak learner to strong learners.\n",
        "\n",
        "There are many boosting algorithms which impart additional boost to model’s accuracy. In this tutorial, we’ll learn about the two most commonly used algorithms i.e. Gradient Boosting (GBM) and XGboost.\n",
        "\n",
        "Generally XGboost is considered more advanced than gbm. \n",
        "- xgboost supports regularization, however gbm does not.\n",
        "- xgboost is blazingley faster than gbm.\n",
        "- xgboost has built-in routine to handle missing values.\n",
        "- xgboost has tree pruning mechanisms,however gbm and random forest are greedy algorithms and do not have tree pruning.\n",
        "- In xgboost we can run cross-validation at each iteration of the boosting. But in gbm, we have to run grid search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqxjhKA10idV",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2rGIoPdzugp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "SEED = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26kct8yYAM5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = 8,8\n",
        "plt.rcParams.update({'font.size': 16})\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L4gBBV1021_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFl05MnlAHnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# six and pickle\n",
        "import six\n",
        "import pickle\n",
        "import joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoHegV7XAD9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scale and split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6TulJuKAAV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classifiers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srUWG5iF01LO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sklearn scalar metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KTU9otw_2_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# roc auc and curves\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import precision_recall_curve"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWiPSeWI_6J5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# confusion matrix and classification report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACwPNWa2d0Ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSe0UCap8NBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK, STATUS_FAIL\n",
        "from hyperopt.pyll import scope\n",
        "from hyperopt.pyll.stochastic import sample\n",
        "import copy\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K8cKDmzFKoP",
        "colab_type": "text"
      },
      "source": [
        "# Useful Scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocBnXJtCFMCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_method_attributes(obj, ncols=7,start=None, inside=None):\n",
        "    \"\"\" Show all the attributes of a given method.\n",
        "    Example:\n",
        "    ========\n",
        "    show_method_attributes(list)\n",
        "     \"\"\"\n",
        "    lst = [elem for elem in dir(obj) if elem[0]!='_' ]\n",
        "    lst = [elem for elem in lst \n",
        "           if elem not in 'os np pd sys time psycopg2'.split() ]\n",
        "\n",
        "    if isinstance(start,str):\n",
        "        lst = [elem for elem in lst if elem.startswith(start)]\n",
        "        \n",
        "    if isinstance(start,tuple) or isinstance(start,list):\n",
        "        lst = [elem for elem in lst for start_elem in start\n",
        "               if elem.startswith(start_elem)]\n",
        "        \n",
        "    if isinstance(inside,str):\n",
        "        lst = [elem for elem in lst if inside in elem]\n",
        "        \n",
        "    if isinstance(inside,tuple) or isinstance(inside,list):\n",
        "        lst = [elem for elem in lst for inside_elem in inside\n",
        "               if inside_elem in elem]\n",
        "\n",
        "    return pd.DataFrame(np.array_split(lst,ncols)).T.fillna('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtPWfjrfZhkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_eval = pd.DataFrame({'Model': [],\n",
        "                        'Description':[],\n",
        "                        'Accuracy':[],\n",
        "                        'Precision':[],\n",
        "                        'Recall':[],\n",
        "                        'F1':[],\n",
        "                        'AUC':[],\n",
        "                    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXHhDh4TzzCj",
        "colab_type": "text"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPOJ1_zV0nrU",
        "colab_type": "code",
        "outputId": "6957a084-6eff-4b5e-9137-bad3edf0f575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "ifile = 'https://github.com/bhishanpdl/Project_Fraud_Detection/blob/master/data/raw/creditcard.csv.zip?raw=true'\n",
        "df = pd.read_csv(ifile,compression='zip')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(284807, 31)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2xN1zIZ0_k-",
        "colab_type": "code",
        "outputId": "fcf5f699-b5a6-45c8-c9da-d24ec54821fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "target = 'Class'\n",
        "df[target].value_counts(normalize=True)*100"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    99.827251\n",
              "1     0.172749\n",
              "Name: Class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTvH3c6a1D8m",
        "colab_type": "text"
      },
      "source": [
        "# Train test split with stratify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AH6lRaO1H-4",
        "colab_type": "code",
        "outputId": "748c2677-fbc3-49b5-8fd6-abd3a5a8a43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtrain_orig, Xtest, ytrain_orig, ytest = train_test_split(\n",
        "    df.drop(target,axis=1), \n",
        "    df[target],\n",
        "    test_size=0.2, \n",
        "    random_state=SEED, \n",
        "    stratify=df[target])\n",
        "\n",
        "df_Xtrain_orig = pd.DataFrame(Xtrain_orig, columns=df.columns.drop(target))\n",
        "df_Xtest = pd.DataFrame(Xtest, columns=df.columns.drop(target))\n",
        "\n",
        "print(df_Xtrain_orig.shape)\n",
        "df_Xtrain_orig.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(227845, 30)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>211885</th>\n",
              "      <td>138616.0</td>\n",
              "      <td>-1.137612</td>\n",
              "      <td>2.345154</td>\n",
              "      <td>-1.767247</td>\n",
              "      <td>0.833982</td>\n",
              "      <td>0.973168</td>\n",
              "      <td>-0.073571</td>\n",
              "      <td>0.802433</td>\n",
              "      <td>0.733137</td>\n",
              "      <td>-1.154087</td>\n",
              "      <td>-0.520340</td>\n",
              "      <td>0.494117</td>\n",
              "      <td>0.799935</td>\n",
              "      <td>0.494576</td>\n",
              "      <td>-0.479666</td>\n",
              "      <td>-0.917177</td>\n",
              "      <td>-0.184117</td>\n",
              "      <td>1.189459</td>\n",
              "      <td>0.937244</td>\n",
              "      <td>0.960749</td>\n",
              "      <td>0.062820</td>\n",
              "      <td>0.114953</td>\n",
              "      <td>0.430613</td>\n",
              "      <td>-0.240819</td>\n",
              "      <td>0.124011</td>\n",
              "      <td>0.187187</td>\n",
              "      <td>-0.402251</td>\n",
              "      <td>0.196277</td>\n",
              "      <td>0.190732</td>\n",
              "      <td>39.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12542</th>\n",
              "      <td>21953.0</td>\n",
              "      <td>-1.028649</td>\n",
              "      <td>1.141569</td>\n",
              "      <td>2.492561</td>\n",
              "      <td>-0.242233</td>\n",
              "      <td>0.452842</td>\n",
              "      <td>-0.384273</td>\n",
              "      <td>1.256026</td>\n",
              "      <td>-0.816401</td>\n",
              "      <td>1.964560</td>\n",
              "      <td>-0.014216</td>\n",
              "      <td>0.432153</td>\n",
              "      <td>-2.140921</td>\n",
              "      <td>2.274477</td>\n",
              "      <td>0.114128</td>\n",
              "      <td>-1.652894</td>\n",
              "      <td>-0.617302</td>\n",
              "      <td>0.243791</td>\n",
              "      <td>-0.426168</td>\n",
              "      <td>-0.493177</td>\n",
              "      <td>0.350032</td>\n",
              "      <td>-0.380356</td>\n",
              "      <td>-0.037432</td>\n",
              "      <td>-0.503934</td>\n",
              "      <td>0.407129</td>\n",
              "      <td>0.604252</td>\n",
              "      <td>0.233015</td>\n",
              "      <td>-0.433132</td>\n",
              "      <td>-0.491892</td>\n",
              "      <td>7.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270932</th>\n",
              "      <td>164333.0</td>\n",
              "      <td>-1.121864</td>\n",
              "      <td>-0.195099</td>\n",
              "      <td>1.282634</td>\n",
              "      <td>-3.172847</td>\n",
              "      <td>-0.761969</td>\n",
              "      <td>-0.287013</td>\n",
              "      <td>-0.586367</td>\n",
              "      <td>0.496182</td>\n",
              "      <td>-2.352349</td>\n",
              "      <td>0.350551</td>\n",
              "      <td>-1.319688</td>\n",
              "      <td>-0.942001</td>\n",
              "      <td>1.082210</td>\n",
              "      <td>-0.425735</td>\n",
              "      <td>0.036748</td>\n",
              "      <td>0.380392</td>\n",
              "      <td>-0.033353</td>\n",
              "      <td>0.204609</td>\n",
              "      <td>-0.801465</td>\n",
              "      <td>-0.113632</td>\n",
              "      <td>-0.328953</td>\n",
              "      <td>-0.856937</td>\n",
              "      <td>-0.056198</td>\n",
              "      <td>0.401905</td>\n",
              "      <td>0.406813</td>\n",
              "      <td>-0.440140</td>\n",
              "      <td>0.152356</td>\n",
              "      <td>0.030128</td>\n",
              "      <td>40.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30330</th>\n",
              "      <td>35874.0</td>\n",
              "      <td>1.094238</td>\n",
              "      <td>-0.760568</td>\n",
              "      <td>-0.392822</td>\n",
              "      <td>-0.611720</td>\n",
              "      <td>-0.722850</td>\n",
              "      <td>-0.851978</td>\n",
              "      <td>-0.185505</td>\n",
              "      <td>-0.095131</td>\n",
              "      <td>-1.122304</td>\n",
              "      <td>0.367009</td>\n",
              "      <td>1.378493</td>\n",
              "      <td>-0.724216</td>\n",
              "      <td>-1.105406</td>\n",
              "      <td>-0.480170</td>\n",
              "      <td>0.220826</td>\n",
              "      <td>1.745743</td>\n",
              "      <td>0.740817</td>\n",
              "      <td>-0.728827</td>\n",
              "      <td>1.016740</td>\n",
              "      <td>0.354148</td>\n",
              "      <td>-0.227392</td>\n",
              "      <td>-1.254285</td>\n",
              "      <td>0.022116</td>\n",
              "      <td>-0.141531</td>\n",
              "      <td>0.114515</td>\n",
              "      <td>-0.652427</td>\n",
              "      <td>-0.037897</td>\n",
              "      <td>0.051254</td>\n",
              "      <td>165.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272477</th>\n",
              "      <td>165107.0</td>\n",
              "      <td>2.278095</td>\n",
              "      <td>-1.298924</td>\n",
              "      <td>-1.884035</td>\n",
              "      <td>-1.530435</td>\n",
              "      <td>-0.649500</td>\n",
              "      <td>-0.996024</td>\n",
              "      <td>-0.466776</td>\n",
              "      <td>-0.438025</td>\n",
              "      <td>-1.612665</td>\n",
              "      <td>1.631133</td>\n",
              "      <td>-1.126000</td>\n",
              "      <td>-0.938760</td>\n",
              "      <td>0.300621</td>\n",
              "      <td>-0.119667</td>\n",
              "      <td>-0.585453</td>\n",
              "      <td>-1.106244</td>\n",
              "      <td>0.690235</td>\n",
              "      <td>-0.124401</td>\n",
              "      <td>-0.075649</td>\n",
              "      <td>-0.341708</td>\n",
              "      <td>0.123892</td>\n",
              "      <td>0.815909</td>\n",
              "      <td>-0.072537</td>\n",
              "      <td>0.784217</td>\n",
              "      <td>0.403428</td>\n",
              "      <td>0.193747</td>\n",
              "      <td>-0.043185</td>\n",
              "      <td>-0.058719</td>\n",
              "      <td>60.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2  ...       V27       V28  Amount\n",
              "211885  138616.0 -1.137612  2.345154  ...  0.196277  0.190732   39.46\n",
              "12542    21953.0 -1.028649  1.141569  ... -0.433132 -0.491892    7.19\n",
              "270932  164333.0 -1.121864 -0.195099  ...  0.152356  0.030128   40.00\n",
              "30330    35874.0  1.094238 -0.760568  ... -0.037897  0.051254  165.85\n",
              "272477  165107.0  2.278095 -1.298924  ... -0.043185 -0.058719   60.00\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzb7P4ZdM3c2",
        "colab_type": "text"
      },
      "source": [
        "# Train Validation with stratify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I96itfQwM7qD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b50497f8-8daf-4d7d-d54e-e478fce5e54f"
      },
      "source": [
        "Xtrain, Xvalid, ytrain, yvalid = train_test_split(\n",
        "    Xtrain_orig, \n",
        "    ytrain_orig,\n",
        "    test_size=0.2, \n",
        "    random_state=SEED, \n",
        "    stratify=ytrain_orig)\n",
        "\n",
        "df_Xtrain = pd.DataFrame(Xtrain, columns=df.columns.drop(target))\n",
        "df_Xvalid = pd.DataFrame(Xvalid, columns=df.columns.drop(target))\n",
        "\n",
        "print(df_Xtrain.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(182276, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIdPv4qAew6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "11cd9995-05b1-4a61-c7a0-82a0948afc3e"
      },
      "source": [
        "# random undersampling\n",
        "n = df[target].value_counts().values[-1]\n",
        "df_under = (df.groupby(target)\n",
        "                .apply(lambda x: x.sample(n,random_state=SEED))\n",
        "                .reset_index(drop=True))\n",
        "\n",
        "Xtrain_orig_under, Xtest_under, ytrain_orig_under, ytest_under = train_test_split(\n",
        "    df_under.drop(target,axis=1),\n",
        "    df_under[target],\n",
        "    test_size=0.2, \n",
        "    random_state=SEED, \n",
        "    stratify=df_under[target])\n",
        "\n",
        "df_Xtrain_orig_under = pd.DataFrame(Xtrain_orig_under, columns=df_under.columns.drop(target))\n",
        "df_Xtest_under = pd.DataFrame(Xtest_under, columns=df_under.columns.drop(target))\n",
        "\n",
        "\n",
        "Xtrain_under, Xvalid_under, ytrain_under, yvalid_under = train_test_split(\n",
        "    Xtrain_orig_under,\n",
        "    ytrain_orig_under,\n",
        "    test_size=0.2, \n",
        "    random_state=SEED, \n",
        "    stratify=ytrain_orig_under)\n",
        "\n",
        "\n",
        "\n",
        "df_Xtrain_under = pd.DataFrame(Xtrain_under, columns=df_under.columns.drop(target))\n",
        "df_Xvalid_under = pd.DataFrame(Xvalid_under, columns=df_under.columns.drop(target))\n",
        "\n",
        "\n",
        "ytrain.value_counts(), ytest.value_counts(), yvalid.value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0    181961\n",
              " 1       315\n",
              " Name: Class, dtype: int64, 0    56864\n",
              " 1       98\n",
              " Name: Class, dtype: int64, 0    45490\n",
              " 1       79\n",
              " Name: Class, dtype: int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33N72LeW1LO7",
        "colab_type": "text"
      },
      "source": [
        "# Modelling xgboost imbalanced data\n",
        "```\n",
        "Parameters:\n",
        "-------------\n",
        "max_depth=3\n",
        "learning_rate=0.1\n",
        "n_estimators=100\n",
        "verbosity=1 **NOTE: it print in ipython terminal not in browser\n",
        "silent=None **deprecated use verbosity\n",
        "objective='binary:logistic' **for binary classification\n",
        "booster='gbtree' **use default tree not linear\n",
        "n_jobs=1 **make this -1\n",
        "nthread=None **deprecated use n_jobs\n",
        "gamma=0\n",
        "min_child_weight=1\n",
        "max_delta_step=0\n",
        "subsample=1\n",
        "colsample_bytree=1\n",
        "colsample_bylevel=1\n",
        "colsample_bynode=1\n",
        "reg_alpha=0\n",
        "reg_lambda=1\n",
        "scale_pos_weight=1\n",
        "base_score=0.5\n",
        "random_state=0 **use your own random state\n",
        "seed=None      **deprecated use random_state\n",
        "missing=None\n",
        "```\n",
        "\n",
        "\n",
        "[early stopping xgboost official note](https://xgboost.readthedocs.io/en/latest/python/python_intro.html):  \n",
        "\n",
        "\n",
        "If early stopping occurs, the model will have three additional fields: bst.best_score, bst.best_iteration and bst.best_ntree_limit.\n",
        " Note that xgboost.train() will return a model from the last iteration, not the best one.\n",
        "[Example](https://github.com/dmlc/xgboost/blob/master/demo/guide-python/sklearn_examples.py)\n",
        "```python\n",
        "clf = xgb.XGBClassifier()\n",
        "clf.fit(X_train, y_train, early_stopping_rounds=10, eval_metric=\"auc\",\n",
        "        eval_set=[(X_test, y_test)])\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axQE4_7YJ2P4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# help(XGBClassifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAMEvv606xeP",
        "colab_type": "code",
        "outputId": "8bb77018-29f4-425f-b23e-bfd1c34bfb91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score,  precision_score, recall_score,f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "time_start = time.time()\n",
        "# model fit\n",
        "clf_xgb = XGBClassifier(n_jobs=-1, random_state=SEED,\n",
        "                        objective='binary:logistic')\n",
        "\n",
        "clf_xgb.fit(df_Xtrain, ytrain)\n",
        "default = \"\"\"\n",
        "[[56852    12]\n",
        " [   30    68]]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# clf_xgb.fit(df_Xtrain,ytrain,\n",
        "#             eval_set=[(df_Xvalid,yvalid)],\n",
        "#             eval_metric='auc',\n",
        "#             early_stopping_rounds=30, # early stopping gives \n",
        "#             )\n",
        "early30 = \"\"\"\n",
        "\n",
        "[[56852    12]\n",
        " [   30    68]]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# predictions\n",
        "skf = StratifiedKFold(n_splits=2,shuffle=True,random_state=SEED)\n",
        "ypreds_cv = cross_val_predict(clf_xgb, Xtest, ytest, cv=skf)\n",
        "ypreds = ypreds_cv\n",
        "\n",
        "\n",
        "\n",
        "# model evaluation\n",
        "row_eval = ['Xgboost','default, imbalanced', \n",
        "            accuracy_score(ytest, ypreds),\n",
        "            precision_score(ytest, ypreds, average='micro'),\n",
        "            recall_score(ytest, ypreds, average='micro'),\n",
        "            f1_score(ytest, ypreds, average='micro'),\n",
        "            roc_auc_score(ytest, ypreds),\n",
        "       ]\n",
        "\n",
        "df_eval.loc[len(df_eval)] = row_eval\n",
        "df_eval = df_eval.drop_duplicates()\n",
        "time_taken = time.time() - time_start\n",
        "print('Time taken: {:.0f} min {:.0f} secs'.format(*divmod(time_taken,60)))\n",
        "display(df_eval)\n",
        "\n",
        "# confusion matrix\n",
        "print(confusion_matrix(ytest, ypreds))\n",
        "print(classification_report(ytest,ypreds))\n",
        "\n",
        "# feature importance\n",
        "fig,ax = plt.subplots(figsize=(12,8))\n",
        "xgb.plot_importance(clf_xgb,ax=ax)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken: 0 min 46 secs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Description</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>default, imbalanced</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.846833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Model          Description  Accuracy  ...    Recall        F1       AUC\n",
              "0  Xgboost  default, imbalanced  0.999263  ...  0.999263  0.999263  0.846833\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[56852    12]\n",
            " [   30    68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.85      0.69      0.76        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.92      0.85      0.88     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAH0CAYAAACEkWPuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVoYTmyVeWKj",
        "colab_type": "text"
      },
      "source": [
        "# Xgboost modelling Undersampled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0lDkh6IgofE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "16c30b29-bbab-430e-d9f6-c98e70d33d52"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score,  precision_score, recall_score,f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "time_start = time.time()\n",
        "# model fit\n",
        "clf_xgb = XGBClassifier(n_jobs=-1, random_state=SEED,\n",
        "                        objective='binary:logistic')\n",
        "\n",
        "clf_xgb.fit(df_Xtrain_under, ytrain_under)\n",
        "\n",
        "\n",
        "# predictions\n",
        "skf = StratifiedKFold(n_splits=2,shuffle=True,random_state=SEED)\n",
        "ypreds_cv = cross_val_predict(clf_xgb, Xtest_under, ytest_under, cv=skf)\n",
        "ypreds_under = ypreds_cv\n",
        "\n",
        "# model evaluation\n",
        "row_eval = ['Xgboost','default, undersample', \n",
        "            accuracy_score(ytest_under, ypreds_under),\n",
        "            precision_score(ytest_under, ypreds_under, average='micro'),\n",
        "            recall_score(ytest_under, ypreds_under, average='micro'),\n",
        "            f1_score(ytest_under, ypreds_under, average='micro'),\n",
        "            roc_auc_score(ytest_under, ypreds_under),\n",
        "       ]\n",
        "\n",
        "df_eval.loc[len(df_eval)] = row_eval\n",
        "df_eval = df_eval.drop_duplicates()\n",
        "time_taken = time.time() - time_start\n",
        "print('Time taken: {:.0f} min {:.0f} secs'.format(*divmod(time_taken,60)))\n",
        "display(df_eval)\n",
        "\n",
        "# confusion matrix\n",
        "print(confusion_matrix(ytest_under, ypreds_under))\n",
        "print(classification_report(ytest_under,ypreds_under))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken: 0 min 0 secs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Description</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>default, imbalanced</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.846833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>default, undersample</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.943981</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Model           Description  Accuracy  ...    Recall        F1       AUC\n",
              "0  Xgboost   default, imbalanced  0.999263  ...  0.999263  0.999263  0.846833\n",
              "1  Xgboost  default, undersample  0.944162  ...  0.944162  0.944162  0.943981\n",
              "\n",
              "[2 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[97  2]\n",
            " [ 9 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95        99\n",
            "           1       0.98      0.91      0.94        98\n",
            "\n",
            "    accuracy                           0.94       197\n",
            "   macro avg       0.95      0.94      0.94       197\n",
            "weighted avg       0.95      0.94      0.94       197\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGUFZlwOh7nJ",
        "colab_type": "text"
      },
      "source": [
        "# Xgboost modelling Undersampled data with n_estimators = 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJPgz2vkj0Fr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "e776f0a7-dafb-4383-b8bb-8379586a0920"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score,  precision_score, recall_score,f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "time_start = time.time()\n",
        "# model fit\n",
        "clf_xgb = XGBClassifier(n_jobs=-1, random_state=SEED,\n",
        "                        objective='binary:logistic',\n",
        "                        n_estimators=150)\n",
        "\n",
        "clf_xgb.fit(df_Xtrain_under, ytrain_under)\n",
        "\n",
        "\n",
        "# predictions\n",
        "skf = StratifiedKFold(n_splits=2,shuffle=True,random_state=SEED)\n",
        "ypreds_cv = cross_val_predict(clf_xgb, Xtest_under, ytest_under, cv=skf)\n",
        "ypreds_under = ypreds_cv\n",
        "\n",
        "# model evaluation\n",
        "row_eval = ['Xgboost','undersample, n_estimators=150', \n",
        "            accuracy_score(ytest_under, ypreds_under),\n",
        "            precision_score(ytest_under, ypreds_under, average='micro'),\n",
        "            recall_score(ytest_under, ypreds_under, average='micro'),\n",
        "            f1_score(ytest_under, ypreds_under, average='micro'),\n",
        "            roc_auc_score(ytest_under, ypreds_under),\n",
        "       ]\n",
        "\n",
        "df_eval.loc[len(df_eval)] = row_eval\n",
        "df_eval = df_eval.drop_duplicates()\n",
        "time_taken = time.time() - time_start\n",
        "print('Time taken: {:.0f} min {:.0f} secs'.format(*divmod(time_taken,60)))\n",
        "display(df_eval)\n",
        "\n",
        "# confusion matrix\n",
        "print(confusion_matrix(ytest_under, ypreds_under))\n",
        "print(classification_report(ytest_under,ypreds_under))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken: 0 min 0 secs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Description</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>default, imbalanced</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.846833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>default, undersample</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.943981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>undersample, n_estimators=150</td>\n",
              "      <td>0.954315</td>\n",
              "      <td>0.954315</td>\n",
              "      <td>0.954315</td>\n",
              "      <td>0.954315</td>\n",
              "      <td>0.954082</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Model                    Description  ...        F1       AUC\n",
              "0  Xgboost            default, imbalanced  ...  0.999263  0.846833\n",
              "1  Xgboost           default, undersample  ...  0.944162  0.943981\n",
              "2  Xgboost  undersample, n_estimators=150  ...  0.954315  0.954082\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[99  0]\n",
            " [ 9 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96        99\n",
            "           1       1.00      0.91      0.95        98\n",
            "\n",
            "    accuracy                           0.95       197\n",
            "   macro avg       0.96      0.95      0.95       197\n",
            "weighted avg       0.96      0.95      0.95       197\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMbed01Nj7Nr",
        "colab_type": "text"
      },
      "source": [
        "# HPO (Hyper Parameter Optimization)\n",
        "\n",
        "**Important Parameters**:\n",
        "\n",
        "- learning_rate: step size shrinkage used to prevent overfitting. Range is [0,1]\n",
        "- max_depth: determines how deeply each tree is allowed to grow during any boosting round.\n",
        "- subsample: percentage of samples used per tree. Low value can lead to underfitting.\n",
        "- colsample_bytree: percentage of features used per tree. High value can lead to overfitting.\n",
        "- n_estimators: number of trees you want to build.\n",
        "\n",
        "\n",
        "**Regularization parameters**:\n",
        "\n",
        "- gamma: controls whether a given node will split based on the expected reduction in loss after the split. A higher value leads to fewer splits. Supported only for tree-based learners.\n",
        "- alpha: L1 regularization on leaf weights. A large value leads to more regularization.\n",
        "- lambda: L2 regularization on leaf weights and is smoother than L1 regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPeudkl4lAq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK, STATUS_FAIL\n",
        "from hyperopt.pyll import scope\n",
        "from hyperopt.pyll.stochastic import sample\n",
        "import copy\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "def hpo_hyperopt(param_space, Xtrain, ytrain, Xtest, ytest, num_eval,cv=3):\n",
        "    \"\"\"HPO using hyperopt package.\n",
        "\n",
        "    Hyper Parameter Optimation using Bayesian methods.\n",
        "\n",
        "    Usage:\n",
        "    -------\n",
        "    num_eval = 500 # number of evaluations\n",
        "    param_hyperopt = {\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 5, 15, 1)),\n",
        "    'n_estimators': scope.int(hp.quniform('n_estimators', 50, 1000, 50)),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 5, 50, 1)),\n",
        "    'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart']),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.2, 1.0),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
        "    }\n",
        "\n",
        "\n",
        "    trials, dict_best_params1 = hpo_hyperopt(param_hyperopt,\n",
        "                                Xtrain_under, ytrain_under,\n",
        "                                Xtest_under, ytest_under, num_eval)\n",
        "\n",
        "    clf_xgb = XGBClassifier(n_jobs=-1, random_state=SEED,\n",
        "                        objective='binary:logistic',\n",
        "                        **dict_best_params1)\n",
        "\n",
        "    \"\"\"\n",
        "    # time\n",
        "    time_start = time.time()\n",
        "    \n",
        "    # define objective function\n",
        "    def objective_function(params):\n",
        "        model = xgb.XGBClassifier(**params)\n",
        "        score = cross_val_score(model, Xtrain, ytrain, cv=cv).mean()\n",
        "        return {'loss': -score, 'status': STATUS_OK}\n",
        "\n",
        "    # keep track of trials\n",
        "    trials = Trials()\n",
        "\n",
        "    # best params\n",
        "    best_param = fmin(objective_function, \n",
        "                      param_space, \n",
        "                      algo=tpe.suggest, \n",
        "                      max_evals=num_eval, \n",
        "                      trials=trials,\n",
        "                      rstate= np.random.RandomState(SEED))\n",
        "    \n",
        "    # dict best params\n",
        "    dict_best_params = copy.copy(best_param)\n",
        "\n",
        "    if 'boosting_type' in dict_best_params: \n",
        "        dict_best_params['boosting_type'] = 'gbdt' if dict_best_params['boosting_type'] == 0 else 'dart'\n",
        "\n",
        "\n",
        "    int_params = ['max_depth','num_leaves','n_estimators']\n",
        "\n",
        "    for int_param in int_params:\n",
        "        # make integer if exist\n",
        "        if int_param in dict_best_params:\n",
        "            dict_best_params[int_param] = int(dict_best_params[int_param])\n",
        "    \n",
        "    # loss\n",
        "    loss = [x['result']['loss'] for x in trials.trials]\n",
        "\n",
        "    # best model    \n",
        "    model_best = xgb.XGBClassifier(**dict_best_params)                      \n",
        "    model_best.fit(Xtrain, ytrain)\n",
        "\n",
        "    time_taken = time.time() - time_start\n",
        "    \n",
        "    print(\"\\nResults\\n\" + '='*50)\n",
        "    print('Time taken: {:.0f} min {:.0f} secs'.format(*divmod(time_taken,60)))\n",
        "    print(\"Number of parameter combinations tested: \", num_eval)\n",
        "    print(\"Train Score Best                       : {:.4f} \".format(min(loss)*-1))\n",
        "    print(\"Test Score                             : {:.4f} \".format(model_best.score(Xtest, ytest)))\n",
        "    print(\"Best parameters:\")\n",
        "    pp.pprint(dict_best_params)\n",
        "    \n",
        "    return trials, dict_best_params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4Us9s9xlW5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "outputId": "a53436ec-4e51-4e2c-fa61-41a6ebe97502"
      },
      "source": [
        "num_eval = 50 # number of evaluations\n",
        "param_hyperopt= {\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 5, 15, 1)),\n",
        "    # 'n_estimators': scope.int(hp.quniform('n_estimators', 150, 151, 1)),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 5, 50, 1)),\n",
        "    'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart']),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.2, 1.0),\n",
        "    'subsample': hp.uniform ('subsample', 0.7, 1),\n",
        "    'min_child_weight': hp.quniform ('min_child_weight', 1, 10, 1),\n",
        "    # regularization\n",
        "    # 'reg_alpha': hp.uniform('reg_alpha', 0.0, 0.1),\n",
        "    # 'reg_lambda': hp.uniform('reg_lambda', 0.0, 0.1),\n",
        "    # 'gamma' : hp.quniform('gamma', 0, 0.50, 0.01),\n",
        "    'gamma' : hp.uniform ('x_gamma', 0.1,0.5),\n",
        "}\n",
        "\n",
        "\n",
        "trials, dict_best_params = hpo_hyperopt(param_hyperopt, \n",
        "                                Xtrain_under, ytrain_under,\n",
        "                                Xtest_under, ytest_under, num_eval)\n",
        "\n",
        "# override best params\n",
        "# dict_best_params['boosting_type'] = 'gbdt'\n",
        "time_start = time.time()\n",
        "# model fit\n",
        "clf_xgb = XGBClassifier(n_jobs=-1, random_state=SEED,\n",
        "                        objective='binary:logistic',\n",
        "                        n_estimators=150,\n",
        "                        **dict_best_params)\n",
        "\n",
        "print(clf_xgb)\n",
        "clf_xgb.fit(df_Xtrain_under, ytrain_under)\n",
        "\n",
        "\n",
        "# predictions\n",
        "skf = StratifiedKFold(n_splits=2,shuffle=True,random_state=SEED)\n",
        "ypreds_cv = cross_val_predict(clf_xgb, Xtest_under, ytest_under, cv=skf)\n",
        "ypreds_under = ypreds_cv\n",
        "\n",
        "# model evaluation\n",
        "row_eval = ['Xgboost','undersample, hpo1', \n",
        "            accuracy_score(ytest_under, ypreds_under),\n",
        "            precision_score(ytest_under, ypreds_under, average='micro'),\n",
        "            recall_score(ytest_under, ypreds_under, average='micro'),\n",
        "            f1_score(ytest_under, ypreds_under, average='micro'),\n",
        "            roc_auc_score(ytest_under, ypreds_under),\n",
        "       ]\n",
        "\n",
        "df_eval.loc[len(df_eval)] = row_eval\n",
        "df_eval = df_eval.drop_duplicates()\n",
        "time_taken = time.time() - time_start\n",
        "print('Time taken: {:.0f} min {:.0f} secs'.format(*divmod(time_taken,60)))\n",
        "display(df_eval)\n",
        "\n",
        "# confusion matrix\n",
        "print(confusion_matrix(ytest_under, ypreds_under))\n",
        "print(classification_report(ytest_under,ypreds_under))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:11<00:00,  3.68it/s, best loss: -0.9316700843016633]\n",
            "\n",
            "Results\n",
            "==================================================\n",
            "Time taken: 0 min 12 secs\n",
            "Number of parameter combinations tested:  50\n",
            "Train Score Best                       : 0.9317 \n",
            "Test Score                             : 0.9391 \n",
            "Best parameters:\n",
            "{   'boosting_type': 'dart',\n",
            "    'colsample_by_tree': 0.6572282885949191,\n",
            "    'learning_rate': 0.08125316309250195,\n",
            "    'max_depth': 14,\n",
            "    'min_child_weight': 4.0,\n",
            "    'num_leaves': 8,\n",
            "    'subsample': 0.7847729344095749,\n",
            "    'x_gamma': 0.33281913864021795}\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', boosting_type='dart',\n",
            "              colsample_by_tree=0.6572282885949191, colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.08125316309250195, max_delta_step=0, max_depth=14,\n",
            "              min_child_weight=4.0, missing=None, n_estimators=150, n_jobs=-1,\n",
            "              nthread=None, num_leaves=8, objective='binary:logistic',\n",
            "              random_state=100, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
            "              seed=None, silent=None, subsample=0.7847729344095749, verbosity=1,\n",
            "              x_gamma=0.33281913864021795)\n",
            "Time taken: 0 min 0 secs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Description</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>default, imbalanced</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.846833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>default, undersample</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.943981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>undersample, n_estimators=150</td>\n",
              "      <td>0.954315</td>\n",
              "      <td>0.954315</td>\n",
              "      <td>0.954315</td>\n",
              "      <td>0.954315</td>\n",
              "      <td>0.954082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>undersample, hpo1</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.943981</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Model                    Description  ...        F1       AUC\n",
              "0  Xgboost            default, imbalanced  ...  0.999263  0.846833\n",
              "1  Xgboost           default, undersample  ...  0.944162  0.943981\n",
              "2  Xgboost  undersample, n_estimators=150  ...  0.954315  0.954082\n",
              "3  Xgboost              undersample, hpo1  ...  0.944162  0.943981\n",
              "\n",
              "[4 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[97  2]\n",
            " [ 9 89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95        99\n",
            "           1       0.98      0.91      0.94        98\n",
            "\n",
            "    accuracy                           0.94       197\n",
            "   macro avg       0.95      0.94      0.94       197\n",
            "weighted avg       0.95      0.94      0.94       197\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY-L8tXp9Soc",
        "colab_type": "text"
      },
      "source": [
        "# HPO Notes\n",
        "```python\n",
        "num_eval = 50\n",
        "param_hyperopt= {\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 5, 15, 1)),\n",
        "    # 'n_estimators': scope.int(hp.quniform('n_estimators', 150, 151, 1)),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 5, 50, 1)),\n",
        "    'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart']),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.2, 1.0),\n",
        "    'subsample': hp.uniform ('subsample', 0.7, 1),\n",
        "    'min_child_weight': hp.quniform ('min_child_weight', 1, 10, 1),\n",
        "    # regularization\n",
        "    #'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
        "    #'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
        "}\n",
        "[[97  2]\n",
        " [ 8 90]]\n",
        " XGBClassifier(base_score=0.5, booster='gbtree', boosting_type='dart',\n",
        "              colsample_by_tree=0.425706475356356, colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "              learning_rate=0.04110731401631858, max_delta_step=0, max_depth=11,\n",
        "              min_child_weight=10.0, missing=None, n_estimators=150, n_jobs=-1,\n",
        "              nthread=None, num_leaves=46, objective='binary:logistic',\n",
        "              random_state=100, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
        "              seed=None, silent=None, subsample=0.9164366853711832,\n",
        "              verbosity=1)\n",
        "              \n",
        "\n",
        "**Warning** \n",
        "with same params but increasing num_eval to 500 gives worse result:\n",
        "[97  2]\n",
        " [10 88]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzMHN28X9Stn",
        "colab_type": "text"
      },
      "source": [
        "# HPO for imbalanced data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v7SWLPXJN8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "outputId": "8109af5e-c0a3-45c8-83a7-3c94e44d59b0"
      },
      "source": [
        "num_eval = 10 # number of evaluations\n",
        "param_hyperopt= {\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(1)),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 5, 15, 1)),\n",
        "    # 'n_estimators': scope.int(hp.quniform('n_estimators', 100, 500, 50)),\n",
        "    'num_leaves': scope.int(hp.quniform('num_leaves', 5, 50, 1)),\n",
        "    'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart']),\n",
        "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.2, 1.0),\n",
        "    'subsample': hp.uniform ('subsample', 0.7, 1),\n",
        "    'min_child_weight': hp.quniform ('min_child_weight', 1, 10, 1),\n",
        "    # regularization\n",
        "    # 'reg_alpha': hp.uniform('reg_alpha', 0.0, 0.1),\n",
        "    # 'reg_lambda': hp.uniform('reg_lambda', 0.0, 0.1),\n",
        "    # 'gamma' : hp.quniform('gamma', 0, 0.50, 0.01),\n",
        "    # 'gamma' : hp.uniform ('gamma', 0.1,0.5),\n",
        "}\n",
        "\n",
        "\n",
        "trials, dict_best_params = hpo_hyperopt(param_hyperopt,\n",
        "                                Xtrain, ytrain,\n",
        "                                Xtest, ytest, num_eval)\n",
        "\n",
        "# override best params\n",
        "# dict_best_params1['boosting_type'] = 'gbdt'\n",
        "time_start = time.time()\n",
        "# model fit\n",
        "clf_xgb = XGBClassifier(n_jobs=-1, random_state=SEED,\n",
        "                        objective='binary:logistic',\n",
        "                        n_estimators=150,\n",
        "                        **dict_best_params)\n",
        "\n",
        "print(clf_xgb)\n",
        "clf_xgb.fit(df_Xtrain, ytrain)\n",
        "\n",
        "\n",
        "# predictions\n",
        "skf = StratifiedKFold(n_splits=2,shuffle=True,random_state=SEED)\n",
        "ypreds_cv = cross_val_predict(clf_xgb, Xtest, ytest, cv=skf)\n",
        "ypreds = ypreds_cv\n",
        "\n",
        "# model evaluation\n",
        "row_eval = ['Xgboost','imbalanced, hpo', \n",
        "            accuracy_score(ytest, ypreds),\n",
        "            precision_score(ytest, ypreds, average='micro'),\n",
        "            recall_score(ytest, ypreds, average='micro'),\n",
        "            f1_score(ytest, ypreds, average='micro'),\n",
        "            roc_auc_score(ytest, ypreds),\n",
        "       ]\n",
        "\n",
        "df_eval.loc[len(df_eval)] = row_eval\n",
        "df_eval = df_eval.drop_duplicates()\n",
        "time_taken = time.time() - time_start\n",
        "print('Time taken: {:.0f} min {:.0f} secs'.format(*divmod(time_taken,60)))\n",
        "display(df_eval)\n",
        "\n",
        "# confusion matrix\n",
        "print(confusion_matrix(ytest, ypreds))\n",
        "print(classification_report(ytest,ypreds))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [1:09:44<00:00, 78.38s/it, best loss: -0.9995830502716553]\n",
            "\n",
            "Results\n",
            "==================================================\n",
            "Time taken: 70 min 57 secs\n",
            "Number of parameter combinations tested:  50\n",
            "Train Score Best                       : 0.9996 \n",
            "Test Score                             : 0.9995 \n",
            "Best parameters:\n",
            "{   'boosting_type': 'gbdt',\n",
            "    'colsample_by_tree': 0.8087884262626683,\n",
            "    'learning_rate': 0.40737521068237276,\n",
            "    'max_depth': 7,\n",
            "    'min_child_weight': 1.0,\n",
            "    'num_leaves': 44,\n",
            "    'subsample': 0.9103436118236479}\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', boosting_type='gbdt',\n",
            "              colsample_by_tree=0.8087884262626683, colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.40737521068237276, max_delta_step=0, max_depth=7,\n",
            "              min_child_weight=1.0, missing=None, n_estimators=150, n_jobs=-1,\n",
            "              nthread=None, num_leaves=44, objective='binary:logistic',\n",
            "              random_state=100, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
            "              seed=None, silent=None, subsample=0.9103436118236479,\n",
            "              verbosity=1)\n",
            "Time taken: 1 min 42 secs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Description</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>default, imbalanced</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.999263</td>\n",
              "      <td>0.846833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>default, undersample</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.943981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>undersample, n_estimators=150</td>\n",
              "      <td>0.954315</td>\n",
              "      <td>0.954315</td>\n",
              "      <td>0.954315</td>\n",
              "      <td>0.954315</td>\n",
              "      <td>0.954082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>undersample, hpo1</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.944162</td>\n",
              "      <td>0.943981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Xgboost</td>\n",
              "      <td>imbalanced, hpo</td>\n",
              "      <td>0.999333</td>\n",
              "      <td>0.999333</td>\n",
              "      <td>0.999333</td>\n",
              "      <td>0.999333</td>\n",
              "      <td>0.846868</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Model                    Description  ...        F1       AUC\n",
              "0  Xgboost            default, imbalanced  ...  0.999263  0.846833\n",
              "1  Xgboost           default, undersample  ...  0.944162  0.943981\n",
              "2  Xgboost  undersample, n_estimators=150  ...  0.954315  0.954082\n",
              "3  Xgboost              undersample, hpo1  ...  0.944162  0.943981\n",
              "4  Xgboost                imbalanced, hpo  ...  0.999333  0.846868\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[56856     8]\n",
            " [   30    68]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.89      0.69      0.78        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.95      0.85      0.89     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_a1Eu_7JvU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}